{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import importlib\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Spotify Popularity Predictor\n",
    "The goal of this project is for a user to be able to lookup a song on spotify and receive a prediction of how popular it is. Originally, we had intended to predict the number of playlists that a song occurred on, but we opted to switch to popularity in order to make the possible unseen values be the entirity of Spotify's library.\n",
    "\n",
    "## Part 1: The Dataset\n",
    "Our dataset is composed of over 2 million songs from spotify that we got from a variety of sources. Currently, each entry contains 10 attributes, one of which is the predicted attribute. These attributes include:\n",
    "- Number of Artists\n",
    "    - With Hip Hop being the dominant force in music right now, and features      being a huge part of Hip Hop, it makes sense to take the number of\n",
    "    features into account \n",
    "- The Primary Artist for the track\n",
    "    - While not inherently useful for models other than Naive Bayes, we can\n",
    "    use the spotify api to get more data about each track like genre and\n",
    "    artist popularity. Genre in particular would be very useful, but since\n",
    "    Spotify attaches multiple to each artist, it will complicate the training\n",
    "    process. There are only ~300k unique artists so getting this information\n",
    "    would be trivial\n",
    "- Release Year\n",
    "    - Obviously different years are going to have different sorts of performing songs, and things that make an older song popular don't neccessariliy translate\n",
    "- Explicit\n",
    "    - It is hard to say how useful this will be, though it will will be useful alongside genre in a decision tree\n",
    "- Danceability\n",
    "    - This is a metric calculated by Spotify for its recommendation system,\n",
    "    but it will probably be quite useful for us\n",
    "- Energy\n",
    "    - Much like Danceability, this one is a calculation by Spotify for their \n",
    "    recommendation system and will likely be useful. Both of these would     \n",
    "    likely be enhanced by adding genre to the mix\n",
    "- Tempo\n",
    "    - The tempo of the song in Beats per Minute. Historically this has been\n",
    "    a good predictor of how much a song gets played on the radio or in a \n",
    "    club\n",
    "- Loudness\n",
    "    - This appears to be the peak volume of the track. Another one that would\n",
    "    be enhanced by genre\n",
    "- Time Signature\n",
    "    - The the number of counts per measure. This will likely help filter out\n",
    "    less popular forms of music such as math rock, free jazz, etc. Songs with\n",
    "    more complex time signatures are usually less popular. 3/4\n",
    "- Popularity\n",
    "    - The attribute we are predicting for. This is a value in the range [0,100]\n",
    "    that has to do with the number of plays and how recent they were. An artist's\n",
    "    top 10 tracks are shown based on this value. Unfortunately, the total number\n",
    "    of plays is not exposed to the API.\n",
    "\n",
    "### Getting the Dataset\n",
    "As mentioned, we originally planned on using the million playlists dataset from spotify to factor in the number of\n",
    "times a track appears on a playlist, but this would have severely limited the unseen instances we could use. The dataset\n",
    "did include over 2 million unique songs though, so we opted to use that as the basis for our dataset. After getting the list\n",
    "of songs, we then needed to query the Spotify Web API for those attributes listed above. The ended up being around 69,000\n",
    "requests and took about 4 hours. Thankfully the API allowed us to query data for multiple songs at a time, which is why there\n",
    "wasn't 4 million requests. Each instance contains info from both the `tracks` endpoint and the `audio-features` endpoint. The\n",
    "`tracks` endpoint takes 50 songs per request, and the `audio-features` endpoint takes 100. Interestingly, more than 70% of\n",
    "the time spent was retrieving the `audio-features` data, despite it making up only ~23,000 of the requests. That means that\n",
    "each request took nearly 5 times as long to complete as the `tracks` requests (~7ms per request compared to ~1.5ms). I'm not\n",
    "sure what caused this, but my best theory is that endpoints are prioritized by usage. Logically the `tracks`, `artists`, and \n",
    "`playlists` endpoints would be the most used and thus have the highest priority in whatever queuing. I considered rate limiting,\n",
    "but as I had several of these requests literally time out, I think that this is a much more reasonable explination, as Spotify\n",
    "sends a 429 with a `Retry-After` header when you perform too many requests.\n",
    "\n",
    "\n",
    "### Example Instance\n",
    "Here is an example instance from the dataset. Attributes are in the order\n",
    "they appear above.\n",
    "\n",
    "```{.json}\n",
    "{\n",
    "    ...,\n",
    "    \"0UaMYEvWZi0ZqiDOoHU3YI\": [\n",
    "        3,\n",
    "        \"2wIVse2owClT7go1WT98tk\",\n",
    "        \"2005\",\n",
    "        226863,\n",
    "        true,\n",
    "        0.904,\n",
    "        0.813,\n",
    "        125.461,\n",
    "        -7.105,\n",
    "        4,\n",
    "        68\n",
    "    ],\n",
    "    ...\n",
    "}\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Part 2: Initial Dataset Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}